{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to outline the initial data preparation before building a price prediction model.\n",
    "The data seen in this notebook was scraped from the autotrader website. This notebook will do the following:\n",
    "\n",
    "- [Load the vehicle features and sellers tables from the database](#read_data)\n",
    "- [Assess dataset](#assess_data)\n",
    "- [Outline the cleaning process prior to EDA](#clean_data)\n",
    "- [Output a cleaner dataset for EDA](#pickle_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from data_cleaning import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read data tables into pandas <a id='read_data'></a>\n",
    "\n",
    "Connect to database and join vehicle features with sellers infomation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = get_data_from_database()\n",
    "full_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Assess data <a id='assess_data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the columns contain nulls and some of the data types are incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage of missing values in each column in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_percentage_nulls(full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['advert_id'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Clean Data <a id='explore_data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns which will not be used for the price prediction model will be dropped.\n",
    "The following columns will be dropped as they uniquely identify each car ad and will lead to overfitting in the model:\n",
    "- advert_id\n",
    "- derivative_id\n",
    "- vehicle_registration_mark \n",
    "- seller_id (not uniquely but still identifies car ads)\n",
    "- seller_name (not uniquely but still identifies car ads)\n",
    "\n",
    "The following columns are not available at the time predictions are made and can lead to data leaks:\n",
    "- price_deviation\n",
    "- price_deviation_type\n",
    "- price_excluding_fees\n",
    "- no_admin_fees\n",
    "- price_rating\n",
    "- price_rating_label\n",
    "\n",
    "The following columns have a lot of data points missing:\n",
    "- max_loading_weight\n",
    "- gross_vehicle_weight\n",
    "- zero_to_sixty_two\n",
    "- zero_to_sixty\n",
    "- minimum_kerb_weight\n",
    "\n",
    "The following columns are not useful as they only have one category:\n",
    "- car_condition (all 'used')\n",
    "- is_dealer_trusted (all False)\n",
    "- country (all 'GB')\n",
    "\n",
    "The following columns will probably not be a good predictor of price:\n",
    "- ad_description\n",
    "- page_url\n",
    "- primary_contact_number\n",
    "- dealer_website\n",
    "- date_scraped\n",
    "- time_scraped\n",
    "\n",
    "The infomation in the following columns is already represented by another column:\n",
    "- manufactured_year_identifier (year)\n",
    "- seller_address_one (lat and long)\n",
    "- seller_address_two (lat and long)\n",
    "- vehicle_location_postcode (lat and long)\n",
    "- seller_postcode (lat and long)\n",
    "\n",
    "The following columns contain inaccurate data:\n",
    "- average_mileage (average based on full dataset on website but only a fraction was scraped)\n",
    "- mileage_deviation\n",
    "- mileage_deviation_type \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_columns(full_df)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning issues\n",
    "\n",
    "- vehicle_location_longitude & vehicle_location_latitude contains the same data as seller_longlat but has more missing values\n",
    "- there are two columns with CO2 emissions\n",
    "- manufactured_year, doors, seats, engine_power, wheelbase, height, legnth, valves, cylinders, top_speed, tax, CO2 emissions are all floats\n",
    "- trim column along with others have missing values\n",
    "- the emission_scheme column only has one 'ULEZ' category (convert to boolean column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine latitude and longitudes into one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values in column\n",
    "df[(df.vehicle_location_longitude.isnull()) & (~df.seller_longlat.isnull())][['vehicle_location_longitude', 'vehicle_location_latitude', 'seller_longlat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()[['vehicle_location_longitude', 'vehicle_location_latitude', 'seller_longlat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = combine_latitudes_and_longitudes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of missing values have increased\n",
    "df2.count()[['vehicle_location_longitude', 'vehicle_location_latitude']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine CO2 emissions into one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[(df2.co2_emissions.isnull()) & (~df2.co2_emission.isnull())][['co2_emission', 'co2_emissions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.count()[['co2_emission', 'co2_emissions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = combine_CO2_columns(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.count()['co2_emissions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert emission_scheme column to boolean to show if a car is ULEZ compliant or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check unique entries in column\n",
    "df2['emission_scheme'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = convert_emission_scheme_to_boolean(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.ulez.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix datatypes of columns, and make data entries lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = clean_round1(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill missing values in trim column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = fill_trim_missing_values(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.trim.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deal with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = drop_rows_with_small_percentage_of_missing_values(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values by imputing mode of groups by make, model, trim and year\n",
    "df3 = fill_columns_with_missing_values(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing values in mileage column to use for number of owners predictions in next cell\n",
    "df3 = df3.dropna(subset=['mileage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = fill_number_of_owners_with_predictions(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = fix_int_datatypes(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output dataset to file <a id='pickle_data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this dataset to a file which will hold the datatypes. There are still nulls in this dataset to preserve as much data as possible \n",
    "before performing exploratory data anaylysis. The effect of dropping nulls vs imputing values will be evaluated for the prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_pickle('eda/car_data.pkl')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "55107866eff93953fdbb2b6f0292ad0a58d5c02f1d5c46ccd62bedde6522e08f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('autotrader': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
